
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Welcome!\nI’m Wenyue Hua, a 4th-year Ph.D. candidate at Rutgers. I’m honored to be advised by Prof. Yongfeng Zhang. I received MA in Linguistics at Rutgers in 2020 (proudly advised by Prof. Adam Jardine) and BA in Linguistics and Philosophy and BS in Mathematics at UCLA in 2018 (proudly advised by Prof. Edward Keenan).\nMy research interests lie in Large Language Models and its various application, such as recommender system, information retrieval, humanity research. I care about the trustworthiness, honesty, safety, and efficiency of LLMs.\n","date":1701907200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1701907200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Welcome!\nI’m Wenyue Hua, a 4th-year Ph.D. candidate at Rutgers. I’m honored to be advised by Prof. Yongfeng Zhang. I received MA in Linguistics at Rutgers in 2020 (proudly advised by Prof.","tags":null,"title":"Wenyue Hua","type":"authors"},{"authors":["Yingqiang Ge","Yujie Ren","Wenyue Hua","Shuyuan Xu","Juntao Tan","Yongfeng Zhang"],"categories":null,"content":" Abstract This paper envisions a revolutionary AIOS-Agent ecosystem, where Large Language Model (LLM) serves as the (Artificial) Intelligent Operating System (IOS, or AIOS)–an operating system “with soul”. Upon this foundation, a diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift from the traditional OS-APP ecosystem. We envision that LLMs impact will not be limited to the AI application level, instead, it will in turn revolutionize the design and implementation of computer system, architecture, software, and programming language, featured by several main concepts. LLM as OS (system-level), Agents as Applications (application-level), Natural Language as Programming Interface (user-level), and Tools as Devices/Libraries (hardware/middleware-level). In this paper, we begin by introducing the architecture and historical evolution of traditional Operating Systems (OS). Then we formalize a conceptual framework for AIOS through “LLM as OS (LLMAO)”, drawing analogies between AIOS components and traditional OS elements. LLM is likened to OS kernel, context window to memory, external storage to file system, hardware tools to peripheral devices, software tools to programming libraries, and user prompts to user commands. Subsequently, we introduce the new AIOS-Agent Ecosystem, where users and developers can easily program Agent Applications (AAPs) using natural language, democratizing the development of and the access to computer software, which is different from the traditional OS-APP ecosystem, where desktop or mobile applications (APPs) have to be programmed by well-trained software developers using professional programming languages. Following this, we explore the diverse scope of Agent Applications. These agents can autonomously perform diverse tasks, showcasing intelligent task-solving ability in various scenarios. We delve into both single agent systems and multi-agent systems, as well as human-agent interaction. Lastly, we posit that the AIOS-Agent ecosystem can gain invaluable insights from the development trajectory of the traditional OS-APP ecosystem. Drawing on these insights, we propose a strategic roadmap for the evolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the future research and development, suggesting systematic progresses of AIOS and its Agent applications.\n","date":1701907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701907200,"objectID":"ea3959db866a0568780b5a0bc2782a08","permalink":"https://Wenyueh.github.io/publication/LLMAO/","publishdate":"2023-12-07T00:00:00Z","relpermalink":"/publication/LLMAO/","section":"publication","summary":"This paper envisions a revolutionary AIOS-Agent ecosystem, where Large Language Model (LLM) serves as the (Artificial) Intelligent Operating System (IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift from the traditional OS-APP ecosystem. We envision that LLMs impact will not be limited to the AI application level, instead, it will in turn revolutionize the design and implementation of computer system, architecture, software, and programming language, featured by several main concepts. LLM as OS (system-level), Agents as Applications (application-level), Natural Language as Programming Interface (user-level), and Tools as Devices/Libraries (hardware/middleware-level). In this paper, we begin by introducing the architecture and historical evolution of traditional Operating Systems (OS). Then we formalize a conceptual framework for AIOS through \"LLM as OS (LLMAO)\", drawing analogies between AIOS components and traditional OS elements. LLM is likened to OS kernel, context window to memory, external storage to file system, hardware tools to peripheral devices, software tools to programming libraries, and user prompts to user commands. Subsequently, we introduce the new AIOS-Agent Ecosystem, where users and developers can easily program Agent Applications (AAPs) using natural language, democratizing the development of and the access to computer software, which is different from the traditional OS-APP ecosystem, where desktop or mobile applications (APPs) have to be programmed by well-trained software developers using professional programming languages. Following this, we explore the diverse scope of Agent Applications. These agents can autonomously perform diverse tasks, showcasing intelligent task-solving ability in various scenarios. We delve into both single agent systems and multi-agent systems, as well as human-agent interaction. Lastly, we posit that the AIOS-Agent ecosystem can gain invaluable insights from the development trajectory of the traditional OS-APP ecosystem. Drawing on these insights, we propose a strategic roadmap for the evolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the future research and development, suggesting systematic progresses of AIOS and its Agent applications.","tags":[],"title":"LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract Artificial Intelligence (AI) aims to emulate Human Intelligence (HI) in combining basic skills to address complex tasks. AI agents is an especially important step the development of AI, which should integrate expert models and external tools for solving intricate problems, a step towards achieving Artificial General Intelligence (AGI). Large Language Models (LLMs) demonstrate notable capabilities in learning and reasoning and are proficient in employing external models, tools, plugins, or APIs for complex problem-solving. LLM-based agents are essentially LLMs enhanced with access to these additional resources.\n","date":1701129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701129600,"objectID":"6c8318064bcaf848627ab86e36351b75","permalink":"https://Wenyueh.github.io/project/Agent/","publishdate":"2023-11-28T00:00:00Z","relpermalink":"/project/Agent/","section":"project","summary":"Artificial Intelligence (AI) aims to emulate Human Intelligence (HI) in combining basic skills to address complex tasks. AI agents is an especially important step the development of AI, which should integrate expert models and external tools for solving intricate problems, a step towards achieving Artificial General Intelligence (AGI). Large Language Models (LLMs) demonstrate notable capabilities in learning and reasoning and are proficient in employing external models, tools, plugins, or APIs for complex problem-solving. LLM-based agents are essentially LLMs enhanced with access to these additional resources.","tags":[],"title":"LLM-based Agent and Multi-agent System","type":"project"},{"authors":["Wenyue Hua","Lizhou Fan","Lingyao Li","Kai Mei","Jianchao Ji","Yingqiang Ge","Libby Hemphill","Yongfeng Zhang"],"categories":null,"content":" Abstract Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs). We propose WarAgent, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems’ abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findings offer data-driven and AI-augmented insights that can redefine how we approach conflict resolution and peacekeeping strategies. The implications stretch beyond historical analysis, offering a blueprint for using AI to understand human history and possibly prevent future international conflicts. Code and data are available at this url.\n","date":1701129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701129600,"objectID":"6aec2c851a505250b9fc9f46304f927d","permalink":"https://Wenyueh.github.io/publication/WarAgent/","publishdate":"2023-11-28T00:00:00Z","relpermalink":"/publication/WarAgent/","section":"publication","summary":"Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs). We propose **WarAgent**, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findings offer data-driven and AI-augmented insights that can redefine how we approach conflict resolution and peacekeeping strategies. The implications stretch beyond historical analysis, offering a blueprint for using AI to understand human history and possibly prevent future international conflicts. Code and data are available at [this url](https://github.com/agiresearch/WarAgent).","tags":[],"title":"War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars","type":"publication"},{"authors":["Shuyuan Xu","Wenyue Hua","Yongfeng Zhang"],"categories":null,"content":" Abstract This paper presents OpenP5, an open-source library for benchmarking foundation models for recommendation under the Pre-train, Personalized Prompt and Predict Paradigm (P5). We consider the implementation of P5 on three dimensions – 1) downstream task, 2) recommendation dataset, and 3) item indexing method. For 1), we provide implementation over two downstream tasks – sequential recommendation and straightforward recommendation. For 2), we surveyed frequently used datasets in recommender system research in recent years and provide implementation on ten datasets. In particular, we provide both single-dataset implementation and the corresponding checkpoints (P5) and another Super P5 (SP5) implementation that is pre-trained on all of the datasets, which supports recommendation across various domains with one model. For 3), we provide implementation of three item indexing methods to create item IDs – random indexing, sequential indexing, and collaborative indexing. We also provide comprehensive evaluation results of the library over the two downstream tasks, the ten datasets, and the three item indexing methods to facilitate reproducibility and future research. We open-source the code and the pre-trained checkpoints of the OpenP5 library at this url.\n","date":1687132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687132800,"objectID":"347e2cd11898875cd540ea074e1008e3","permalink":"https://Wenyueh.github.io/publication/openp5/","publishdate":"2023-06-19T00:00:00Z","relpermalink":"/publication/openp5/","section":"publication","summary":"This paper presents OpenP5, an open-source library for benchmarking foundation models for recommendation under the Pre-train, Personalized Prompt and Predict Paradigm (P5). We consider the implementation of P5 on three dimensions -- 1) downstream task, 2) recommendation dataset, and 3) item indexing method. For 1), we provide implementation over two downstream tasks -- sequential recommendation and straightforward recommendation. For 2), we surveyed frequently used datasets in recommender system research in recent years and provide implementation on ten datasets. In particular, we provide both single-dataset implementation and the corresponding checkpoints (P5) and another Super P5 (SP5) implementation that is pre-trained on all of the datasets, which supports recommendation across various domains with one model. For 3), we provide implementation of three item indexing methods to create item IDs -- random indexing, sequential indexing, and collaborative indexing. We also provide comprehensive evaluation results of the library over the two downstream tasks, the ten datasets, and the three item indexing methods to facilitate reproducibility and future research. We open-source the code and the pre-trained checkpoints of the OpenP5 library at [this url](https://github.com/agiresearch/OpenP5).","tags":[],"title":"OpenP5: Benchmarking Foundation Models for Recommendation","type":"publication"},{"authors":["Wenyue Hua","Shuyuan Xu","Yingqiang Ge","Yongfeng Zhang"],"categories":null,"content":" Abstract Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at this url.\n","date":1683763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683763200,"objectID":"08dd04d4221e0c6c57dbe81260cb5eb1","permalink":"https://Wenyueh.github.io/publication/indexing/","publishdate":"2023-05-11T00:00:00Z","relpermalink":"/publication/indexing/","section":"publication","summary":"Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at [this url](https://github.com/Wenyueh/LLM-RecSys-ID).","tags":[],"title":"How to Index Item IDs for Recommendation Foundation Models","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract The integration of foundation models like Large Language Models (LLMs) into recommender systems (RS) marks a significant advancement in the field. Adapting LLMs to recommender systems that manage billions of users and items presents a complex yet crucial challenge. This exploration delves into the benefits and potential issues of utilizing LLMs within recommender systems, contributing to advancements in this area.\n","date":1683676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683676800,"objectID":"5924cdc2bcf731527540c4e39d02d51f","permalink":"https://Wenyueh.github.io/project/LLM4RS/","publishdate":"2023-05-10T00:00:00Z","relpermalink":"/project/LLM4RS/","section":"project","summary":"The integration of foundation models like Large Language Models (LLMs) into recommender systems (RS) marks a significant advancement in the field. Adapting LLMs to recommender systems that manage billions of users and items presents a complex yet crucial challenge. This exploration delves into the benefits and potential issues of utilizing LLMs within recommender systems, contributing to advancements in this area.","tags":[],"title":"LLM for Recommender System","type":"project"},{"authors":["Yingqiang Ge","Wenyue Hua","Kai Mei","Jianchao Ji","Juntao Tan","Shuyuan Xu","Zelong Li","Yongfeng Zhang"],"categories":null,"content":" Abstract Human Intelligence (HI) excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive AI Agents, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models, tools, plugins, or APIs to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research and development platform designed for solving multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools, plugins, or APIs for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM’s task-solving ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project’s code, dataset, benchmarks, evaluation methods, and the UI demo to foster community involvement in AGI advancement this url.\n","date":1681084800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681084800,"objectID":"09d1abff74ecea69b67c8937a72ec53d","permalink":"https://Wenyueh.github.io/publication/OpenAGI/","publishdate":"2023-04-10T00:00:00Z","relpermalink":"/publication/OpenAGI/","section":"publication","summary":"Human Intelligence (HI) excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive AI Agents, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models, tools, plugins, or APIs to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research and development platform designed for solving multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools, plugins, or APIs for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM's task-solving ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation methods, and the UI demo to foster community involvement in AGI advancement here [this url](https://github.com/agiresearch/OpenAGI).","tags":[],"title":"OpenAGI: When LLM Meets Domain Experts","type":"publication"},{"authors":["Wenyue Hua","Yingqiang Ge","Shuyuan Xu","Jianchao Ji","Zelong Li","Yongfeng Zhang"],"categories":null,"content":" Abstract Recent advancements in foundation models such as large language models (LLM) have propelled them to the forefront of recommender systems (RS). Moreover, fairness in RS is critical since many users apply it for decision-making and demand fulfillment. However, at present, there is a lack of understanding regarding the level of fairness exhibited by recommendation foundation models and the appropriate methods for equitably treating different groups of users in foundation models. In this paper, we focus on user-side unfairness problem and show through a thorough examination that there is unfairness involved in LLMs that lead to unfair recommendation results. To eliminate bias from LLM for fairness-aware recommendation, we introduce a novel Unbiased P5 (UP5) foundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP includes two sub-modules: a personalized prefix prompt that enhances fairness with respect to individual sensitive attributes, and a Prompt Mixture that integrates multiple counterfactually-fair prompts for a set of sensitive attributes. Experiments are conducted on two real-world datasets, MovieLens-1M and Insurance, and results are compared with both matching-based and sequential-based fairness-aware recommendation models. The results show that UP5 achieves better recommendation performance and meanwhile exhibits a high level of fairness.\n","date":1674172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674172800,"objectID":"a1ad4bca22cec1ee4a1afe1918e40519","permalink":"https://Wenyueh.github.io/publication/fairness/","publishdate":"2023-01-20T00:00:00Z","relpermalink":"/publication/fairness/","section":"publication","summary":"Recent advancements in foundation models such as large language models (LLM) have propelled them to the forefront of recommender systems (RS). Moreover, fairness in RS is critical since many users apply it for decision-making and demand fulfillment. However, at present, there is a lack of understanding regarding the level of fairness exhibited by recommendation foundation models and the appropriate methods for equitably treating different groups of users in foundation models. In this paper, we focus on user-side unfairness problem and show through a thorough examination that there is unfairness involved in LLMs that lead to unfair recommendation results. To eliminate bias from LLM for fairness-aware recommendation, we introduce a novel Unbiased P5 (UP5) foundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP includes two sub-modules -- a personalized prefix prompt that enhances fairness with respect to individual sensitive attributes, and a Prompt Mixture that integrates multiple counterfactually-fair prompts for a set of sensitive attributes. Experiments are conducted on two real-world datasets, MovieLens-1M and Insurance, and results are compared with both matching-based and sequential-based fairness-aware recommendation models. The results show that UP5 achieves better recommendation performance and meanwhile exhibits a high level of fairness.","tags":[],"title":"UP5: Unbiased Foundation Model for Fairness-aware Recommendation","type":"publication"},{"authors":["Wenyue Hua","Lifeng Jin","Lingfeng Song","Haitao Mi","Yongfeng Zhang","Dong Yu"],"categories":null,"content":" Abstract Current natural language processing (NLP) models such as BERT and RoBERTa have achieved high overall performance, but they often make systematic errors due to bias or certain difficult features to learn. Thus research on slice detection models (SDM) which automatically identifies underperforming groups of datapoints has gradually caught more attention, which aims at both understanding model behaviors and providing insights for future model training and designing. However, there is little systematic research on SDM and quantitative evaluation of its assessment for NLP models. Our paper fills this gap by proposing “Discover, Explanation, Improvement” framework that discovers coherent and underperforming groups of datapoints and unites datapoints of each slice under human-understandable concepts; it also provides comprehensive evaluation tasks and the corresponding quantitative metrics, which enable convenient comparison for future works. Results show that our framework can accurately select error-prone datapoints with informative semantic features that summarize error patterns, based on which it directly boosts model performance by an average of 2.85 points based on trained models without tuning any parameters across multiple datasets.\n","date":1672444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672444800,"objectID":"e89c80ce52e9a1867cf5944473e00a69","permalink":"https://Wenyueh.github.io/publication/domino/","publishdate":"2022-12-31T00:00:00Z","relpermalink":"/publication/domino/","section":"publication","summary":"Current natural language processing (NLP) models such as BERT and RoBERTa have achieved high overall performance, but they often make systematic errors due to bias or certain difficult features to learn. Thus research on slice detection models (SDM) which automatically identifies underperforming groups of datapoints has gradually caught more attention, which aims at both understanding model behaviors and providing insights for future model training and designing. However, there is little systematic research on SDM and quantitative evaluation of its assessment for NLP models. Our paper fills this gap by proposing \"Discover, Explanation, Improvement\" framework that discovers coherent and underperforming groups of datapoints and unites datapoints of each slice under human-understandable concepts; it also provides comprehensive evaluation tasks and the corresponding quantitative metrics, which enable convenient comparison for future works. Results show that our framework can accurately select error-prone datapoints with informative semantic features that summarize error patterns, based on which it directly boosts model performance by an average of 2.85 points based on trained models without tuning any parameters across multiple datasets.","tags":[],"title":"Discover, Explanation, Improvement: Automatic Slice Detection Framework for Natural Language Processing","type":"publication"},{"authors":["Wenyue Hua","Yongfeng Zhang"],"categories":null,"content":" Abstract Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science—which proposes that human cognition process involves two stages: an intuitive, unconscious and fast process relying on perception calledSystem 1, and a logical, conscious and slow process performing complex reasoning called System 2—we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks.\n","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656374400,"objectID":"bdf4e9bac9b71aba71123848fef4e817","permalink":"https://Wenyueh.github.io/publication/system12/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/publication/system12/","section":"publication","summary":"Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science—which proposes that human cognition process involves two stages -- an intuitive, unconscious and fast process relying on perception calledSystem 1, and a logical, conscious and slow process performing complex reasoning called System 2—we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks.","tags":[],"title":"System 1+ System 2= Better World: Neural-Symbolic Chain of Logic Reasoning","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract Some works before the advent of giant LLM …\n","date":1652140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652140800,"objectID":"d0579308de9f085612289c79d71c1c69","permalink":"https://Wenyueh.github.io/project/pre-LLM-NLP/","publishdate":"2022-05-10T00:00:00Z","relpermalink":"/project/pre-LLM-NLP/","section":"project","summary":"Some works before the giant LLM ...","tags":[],"title":"pre-LLM NLP","type":"project"},{"authors":["Wenzheng Zhang","Wenyue Hua","Karl Stratos"],"categories":null,"content":" Abstract A conventional approach to entity linking is to first find mentions in a given document and then infer their underlying entities in the knowledge base. A well-known limitation of this approach is that it requires finding mentions without knowing their entities, which is unnatural and difficult. We present a new model that does not suffer from this limitation called EntQA, which stands for Entity linking as Question Answering. EntQA first proposes candidate entities with a fast retrieval module, and then scrutinizes the document to find mentions of each candidate with a powerful reader module. Our approach combines progress in entity linking with that in open-domain question answering and capitalizes on pretrained models for dense entity retrieval and reading comprehension. Unlike in previous works, we do not rely on a mention-candidates dictionary or large-scale weak supervision. EntQA achieves strong results on the GERBIL benchmarking platform.\n","date":1632960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632960000,"objectID":"c209a6ce61d116a64a42f116584ca669","permalink":"https://Wenyueh.github.io/publication/entqa/","publishdate":"2021-09-30T00:00:00Z","relpermalink":"/publication/entqa/","section":"publication","summary":"A conventional approach to entity linking is to first find mentions in a given document and then infer their underlying entities in the knowledge base. A well-known limitation of this approach is that it requires finding mentions without knowing their entities, which is unnatural and difficult. We present a new model that does not suffer from this limitation called EntQA, which stands for Entity linking as Question Answering. EntQA first proposes candidate entities with a fast retrieval module, and then scrutinizes the document to find mentions of each candidate with a powerful reader module. Our approach combines progress in entity linking with that in open-domain question answering and capitalizes on pretrained models for dense entity retrieval and reading comprehension. Unlike in previous works, we do not rely on a mention-candidates dictionary or large-scale weak supervision. EntQA achieves strong results on the GERBIL benchmarking platform.","tags":[],"title":"EntQA: Entity linking as question answering","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract Formal linguistics is a branch of linguistics that focuses on the study of language using formal methods derived from mathematics and logic. It aims to understand the underlying structure of language by constructing precise, well-defined models of its syntax, semantics, and phonology. The key aspects of formal linguistics include (1) Syntax – This involves the study of the rules and principles that govern the structure of sentences. Formal syntactic theories explore how words combine to form grammatical sentences and the underlying rules that govern these combinations. (2) Semantics – This aspect deals with the meaning of words, phrases, and sentences. Formal semantics seeks to represent and analyze the ways in which linguistic expressions can convey different meanings in different contexts. (3) Phonology – This is the study of the sound systems of languages, including the rules for combining sounds into meaningful units or words. Formal phonology models the abstract sound structures of language and their functional roles.\n","date":1606521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606521600,"objectID":"4d8efa444705759e8daeceb6c1bc3c1e","permalink":"https://Wenyueh.github.io/project/linguistics/","publishdate":"2020-11-28T00:00:00Z","relpermalink":"/project/linguistics/","section":"project","summary":"Formal linguistics is a branch of linguistics that focuses on the study of language using formal methods derived from mathematics and logic. It aims to understand the underlying structure of language by constructing precise, well-defined models of its syntax, semantics, and phonology. The key aspects of formal linguistics include (1) Syntax -- This involves the study of the rules and principles that govern the structure of sentences. Formal syntactic theories explore how words combine to form grammatical sentences and the underlying rules that govern these combinations. (2) Semantics -- This aspect deals with the meaning of words, phrases, and sentences. Formal semantics seeks to represent and analyze the ways in which linguistic expressions can convey different meanings in different contexts. (3) Phonology -- This is the study of the sound systems of languages, including the rules for combining sounds into meaningful units or words. Formal phonology models the abstract sound structures of language and their functional roles.","tags":[],"title":"Formal Linguistics and Computational Linguistics","type":"project"},{"authors":["Wenyue Hua","Adam Jardine"],"categories":null,"content":" Abstract This paper studies the learning of two functions given positive samples of their composition, motivated by an empirical problem in natural language phonology. Empirically relevant conditions under which this is possible are identified and a provably correct algorithm is given that can semi-strongly identify the two functions in polynomial time and data. In order to clearly illustrate the learning problem and related concepts, we focus on a simple subset of input strictly 2-local functions. But we further argue that the general learning procedure we propose can be extended to more general classes of functions.\n","date":1605830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605830400,"objectID":"6b2ff79205557860b2968e13f0b7bef9","permalink":"https://Wenyueh.github.io/publication/icgi/","publishdate":"2020-11-20T00:00:00Z","relpermalink":"/publication/icgi/","section":"publication","summary":"This paper studies the learning of two functions given positive samples of their composition, motivated by an empirical problem in natural language phonology. Empirically relevant conditions under which this is possible are identified and a provably correct algorithm is given that can semi-strongly identify the two functions in polynomial time and data. In order to clearly illustrate the learning problem and related concepts, we focus on a simple subset of input strictly 2-local functions. But we further argue that the general learning procedure we propose can be extended to more general classes of functions.","tags":[],"title":"Learning input strictly local functions from their composition","type":"publication"},{"authors":["Wenyue Hua","Adam Jardine","Huteng Dai"],"categories":null,"content":" Abstract The simultaneous inference of underlying representations (URs) and a phonological grammar from alternating surface representations (SRs) in a morphological paradigm is a core problem in phonological learning that only recently has seen progress (Tesar, 2014; Cotterell et al., 2015; Rasin et al., 2018). This paper proposes a learning algorithm that infers URs and phonological processes from SRs based on the hypothesis that phonological generalizations belong to restrictive subregular regions in the Chomsky Hierarchy (Heinz, 2018). We give a procedure that, given sequences of morphemes paired with SRs, learns URs and a phonological grammar that is an input strictly local (ISL; Chandlee, 2014; Chandlee \u0026amp; Heinz, 2018) function. ISL functions are exactly those which make changes in the output with respect to the local information in the input. For now, the procedure is restricted to simplex ISL processes; that is, those exhibiting a single change. However, this illustrates that restrictive computational principles, combined with major principles in phonological analysis, allow for significant progress in understanding how phonological grammars and URs are learned. The paper is organized as follows. Section 2 briefly introduces the paradigm of the learning algorithm. Section 3 discusses the computational structure encoded in the learner. Section 4 is a detailed explanation of the algorithm with a simple example as illustration. Section 5 compares this algorithm with other algorithms and presents its advantages. The last section concludes the paper.\n","date":1605830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605830400,"objectID":"0f029bc173364a24f87fafa83cf9dfe3","permalink":"https://Wenyueh.github.io/publication/underlying/","publishdate":"2020-11-20T00:00:00Z","relpermalink":"/publication/underlying/","section":"publication","summary":"The simultaneous inference of underlying representations (URs) and a phonological grammar from alternating surface representations (SRs) in a morphological paradigm is a core problem in phonological learning that only recently has seen progress (Tesar, 2014; Cotterell et al., 2015; Rasin et al., 2018). This paper proposes a learning algorithm that infers URs and phonological processes from SRs based on the hypothesis that phonological generalizations belong to restrictive subregular regions in the Chomsky Hierarchy (Heinz, 2018). We give a procedure that, given sequences of morphemes paired with SRs, learns URs and a phonological grammar that is an input strictly local (ISL; Chandlee, 2014; Chandlee \u0026 Heinz, 2018) function. ISL functions are exactly those which make changes in the output with respect to the local information in the input. For now, the procedure is restricted to simplex ISL processes; that is, those exhibiting a single change. However, this illustrates that restrictive computational principles, combined with major principles in phonological analysis, allow for significant progress in understanding how phonological grammars and URs are learned. The paper is organized as follows. Section 2 briefly introduces the paradigm of the learning algorithm. Section 3 discusses the computational structure encoded in the learner. Section 4 is a detailed explanation of the algorithm with a simple example as illustration. Section 5 compares this algorithm with other algorithms and presents its advantages. The last section concludes the paper.","tags":[],"title":"Learning Underlying Representations and Input-Strictly-Local Functions","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract In addition to the substance in phonology, a number of researchers have argued that computation also matters in phonology. Using the data in Yavapai (Yuman language), I show that other than an OT analysis focusing mainly on substance, a computational analysis is necessary for explaining the complex syllabification processes and the frequencies of optional surface representations due to different syllabifications. I will use computational complexity encoded in subregular hierarchy as the main technical tool in the computational analysis. Our main hypothesis is that when both SRs are well-formed based on the syllable phonotactics, the one less complex to generate is more frequently attested. The paper shows that the syllabification pattern in Yavapai necessarily requires a computational motivation, which in turn shows that computational property is a crucial factor in phonological transformations.\n","date":1574208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574208000,"objectID":"adb426931ef1a3a35d2da474f34a2810","permalink":"https://Wenyueh.github.io/publication/yavapai/","publishdate":"2019-11-20T00:00:00Z","relpermalink":"/publication/yavapai/","section":"publication","summary":"In addition to the substance in phonology, a number of researchers have argued that computation also matters in phonology. Using the data in Yavapai (Yuman language), I show that other than an OT analysis focusing mainly on substance, a computational analysis is necessary for explaining the complex syllabification processes and the frequencies of optional surface representations due to different syllabifications. I will use computational complexity encoded in subregular hierarchy as the main technical tool in the computational analysis. Our main hypothesis is that when both SRs are well-formed based on the syllable phonotactics, the one less complex to generate is more frequently attested. The paper shows that the syllabification pattern in Yavapai necessarily requires a computational motivation, which in turn shows that computational property is a crucial factor in phonological transformations.","tags":[],"title":"Computational Complexity in Optional Syllabification of Yavapai","type":"publication"},{"authors":["Wenyue Hua"],"categories":null,"content":" Abstract Disjunction is used to connect multiple options when there is insufficient information to determine which one is true. However, free choice disjunction defies this simple fact – when a disjunction acts as a free choice operator, all options are true. The usage of free choice disjunction is observed to usually co-occur with modals, pluralities, etc. This paper introduces a novel observation of sentences with free choice disjunction in English. Multiple data points are presented to demonstrate the semantic distribution. I propose that free choice reading in disjunctions depends on three factors –the sentence’s genericity, scope of the disjunction and disjuncts being imperfect nominals.\n","date":1561852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561852800,"objectID":"0027027aa0cc13c53bf3c9e1140c5771","permalink":"https://Wenyueh.github.io/publication/freechoice/","publishdate":"2019-06-30T00:00:00Z","relpermalink":"/publication/freechoice/","section":"publication","summary":"Disjunction is used to connect multiple options when there is insufficient information to determine which one is true. However, free choice disjunction defies this simple fact -- when a disjunction acts as a free choice operator, all options are true. The usage of free choice disjunction is observed to usually co-occur with modals, pluralities, etc. This paper introduces a novel observation of sentences with free choice disjunction in English. Multiple data points are presented to demonstrate the semantic distribution. I propose that free choice reading in disjunctions depends on three factors --the sentence’s genericity, scope of the disjunction and disjuncts being imperfect nominals.","tags":[],"title":"Free choice disjunction of propositions in generic sentences","type":"publication"},{"authors":["Mingming Sun","Wenyue Hua","Zoey Liu","Xin Wang","Kangjie Zheng","Ping Li"],"categories":null,"content":" Abstract Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution–Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.\n","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560988800,"objectID":"49ece731e6a8a530861894960f0e4ea7","permalink":"https://Wenyueh.github.io/publication/predicate/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/publication/predicate/","section":"publication","summary":"Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution–Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.","tags":[],"title":"A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://Wenyueh.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://Wenyueh.github.io/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"Hello!","tags":null,"title":"Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://Wenyueh.github.io/research/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"Hello!","tags":null,"title":"My Research","type":"widget_page"}]