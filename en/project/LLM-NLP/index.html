<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: October 2, 2025 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&family=Raleway:ital,wght@0,100..900;1,100..900&family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&family=Raleway:ital,wght@0,100..900;1,100..900&family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0960b1f4b3ca6096de938bdab698fe91.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



























  
  
  






  <meta name="author" content="Wenyue Hua" />





  

<meta name="description" content="Large language models (LLMs) like OpenAI&#39;s GPT series have revolutionized the field of natural language processing (NLP) by demonstrating an impressive ability to understand and generate human language. A key aspect of these models is their reasoning ability, which is a subject of growing interest and investigation. I am particularly focused on exploring the reasoning capabilities in LLMs. This includes understanding the mechanisms that facilitate reasoning within these models, assessing the extent to which LLMs are capable of conducting reasoning processes, and discerning between genuine reasoning and the mere mimicking of patterns observed in pre-trained data." />



<link rel="alternate" hreflang="en-us" href="https://Wenyueh.github.io/en/project/LLM-NLP/" />
<link rel="canonical" href="https://Wenyueh.github.io/en/project/LLM-NLP/" />



  <link rel="manifest" href="/en/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu28e75b20e0960b59a80b3957130a4393_3130320_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu28e75b20e0960b59a80b3957130a4393_3130320_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  






<meta property="twitter:card" content="summary_large_image" />

  <meta property="twitter:site" content="@a" />
  <meta property="twitter:creator" content="@a" />
<meta property="twitter:image" content="https://Wenyueh.github.io/en/project/LLM-NLP/featured.png" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="Wenyue Hua&#39;s Homepage" />
<meta property="og:url" content="https://Wenyueh.github.io/en/project/LLM-NLP/" />
<meta property="og:title" content="LLM &amp; NLP | Wenyue Hua&#39;s Homepage" />
<meta property="og:description" content="Large language models (LLMs) like OpenAI&#39;s GPT series have revolutionized the field of natural language processing (NLP) by demonstrating an impressive ability to understand and generate human language. A key aspect of these models is their reasoning ability, which is a subject of growing interest and investigation. I am particularly focused on exploring the reasoning capabilities in LLMs. This includes understanding the mechanisms that facilitate reasoning within these models, assessing the extent to which LLMs are capable of conducting reasoning processes, and discerning between genuine reasoning and the mere mimicking of patterns observed in pre-trained data." /><meta property="og:image" content="https://Wenyueh.github.io/en/project/LLM-NLP/featured.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-12-22T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-12-22T00:00:00&#43;00:00">
  






    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Wenyueh.github.io/en/project/LLM-NLP/"
  },
  "headline": "LLM \u0026 NLP",
  
  "image": [
    "https://Wenyueh.github.io/en/project/LLM-NLP/featured.png"
  ],
  
  "datePublished": "2023-12-22T00:00:00Z",
  "dateModified": "2023-12-22T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Wenyue Hua"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Wenyue Hua's Homepage",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Wenyueh.github.io/media/icon_hu28e75b20e0960b59a80b3957130a4393_3130320_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Large language models (LLMs) like OpenAI's GPT series have revolutionized the field of natural language processing (NLP) by demonstrating an impressive ability to understand and generate human language. A key aspect of these models is their reasoning ability, which is a subject of growing interest and investigation. I am particularly focused on exploring the reasoning capabilities in LLMs. This includes understanding the mechanisms that facilitate reasoning within these models, assessing the extent to which LLMs are capable of conducting reasoning processes, and discerning between genuine reasoning and the mere mimicking of patterns observed in pre-trained data."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>LLM &amp; NLP | Wenyue Hua&#39;s Homepage</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="c39c7149c0b63887ff6f15c3e6386925" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.92633a219ad78ae82da32b916d6b3338.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/en/">Wenyue Hua&#39;s Homepage</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/en/">Wenyue Hua&#39;s Homepage</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#about"><span>About</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/research/"><span>Research</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/publication/"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/blogs"><span>Blog</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/contact/"><span>Contact</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/uploads/resume.pdf"><span>CV</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article article-project">

  






















  
  



<div class="article-container pt-3">
  <h1>LLM &amp; NLP</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Wenyue Hua</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Dec 22, 2023
  </span>
  

  

  

  
  
  
  

  
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 475px;">
  <div style="position: relative">
    <img src="/en/project/LLM-NLP/featured_hu4d9952460139f50438094216d527c2af_1098213_1d6f2523321fc6bbec6d10e40df947f6.webp" width="720" height="475" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <!-- 

<div class="alert alert-note">
  <div>
    Click the <em>Cite</em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  </div>
</div>




<div class="alert alert-note">
  <div>
    Create your slides in Markdown - click the <em>Slides</em> button to check out the example.
  </div>
</div>
 -->
<h2 id="abstract">Abstract</h2>
<p>Large language models (LLMs) like OpenAI&rsquo;s GPT series have revolutionized the field of natural language processing (NLP) by demonstrating an impressive ability to understand and generate human language. A key aspect of these models is their reasoning ability, which is a subject of growing interest and investigation. I am particularly focused on exploring the reasoning capabilities in LLMs. This includes understanding the mechanisms that facilitate reasoning within these models, assessing the extent to which LLMs are capable of conducting reasoning processes, and discerning between genuine reasoning and the mere mimicking of patterns observed in pre-trained data.</p>

    </div>

    







<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F&amp;text=LLM&#43;%26&#43;NLP" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F&amp;t=LLM&#43;%26&#43;NLP" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=LLM%20%26%20NLP&amp;body=https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F&amp;title=LLM&#43;%26&#43;NLP" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=LLM&#43;%26&#43;NLP%20https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2FWenyueh.github.io%2Fen%2Fproject%2FLLM-NLP%2F&amp;title=LLM&#43;%26&#43;NLP" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://Wenyueh.github.io/"><img class="avatar mr-3 avatar-circle" src="/en/authors/admin/avatar_hu0069b58a5f3f511ad33a3be583f6dc69_80305_270x270_fill_q75_lanczos_center.jpeg" alt="Wenyue Hua"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://Wenyueh.github.io/">Wenyue Hua</a></h5>
      <h6 class="card-subtitle">Senior Researcher</h6>
      <p class="card-text">Ph.D. in Computer Science, focused on large language models.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:wenyue.hua@rutgers.edu" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/HuaWenyue31539" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/Wenyueh" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=Yqw8P-QAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener">
        <i class="fab fa-google scholar"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      
        <h2>Publications</h2>
        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/testtimescaling/" >A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?</a>
    </div>

    
    <a href="/en/publication/testtimescaling/"  class="summary-link">
      <div class="article-style">
        As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as ``test-time computing&rsquo;&rsquo; has emerged as a prominent research focus. Recent studies demonstrate that TTS can further elicit the problem-solving capabilities of large language models (LLMs), enabling significant breakthroughs not only in specialized reasoning tasks, such as mathematics and coding, but also in general tasks like open-ended Q&amp;A. However, despite the explosion of recent efforts in this area, there remains an urgent need for a comprehensive survey offering a systemic understanding. To fill this gap, we propose a unified, multidimensional framework structured along four core dimensions of TTS research &ndash; what to scale, how to scale, where to scale, and how well to scale. Building upon this taxonomy, we conduct an extensive review of methods, application scenarios, and assessment aspects, and present an organized decomposition that highlights the unique functional roles of individual techniques within the broader TTS landscape. From this analysis, we distill the major developmental trajectories of TTS to date and offer hands-on guidelines for practical deployment. Furthermore, we identify several open challenges and offer insights into promising future directions, including further scaling, clarifying the functional essence of techniques, generalizing to more tasks, and more attributions.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Qiyuan Zhang</span>, <span >
      Fuyuan Lyu</span>, <span >
      Zexu Sun</span>, <span >
      Lei Wang</span>, <span >
      Weixu Zhang</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Haolun Wu</span>, <span >
      Zhihan Guo</span>, <span >
      Yufei Wang</span>, <span >
      Niklas Muennighoff</span>, <span >
      Irwin King</span>, <span >
      Xue Liu</span>, <span >
      Chen Ma</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2503.24235" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/testtimescaling/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/testtimescaling/testtimescaling.github.io/" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/testtimescaling/" >
        <img src="/en/publication/testtimescaling/featured_huae8f02df9f356c6f67674116d916a7dd_904380_e921b2c7c56f5c6fb96e25764a7f27f9.webp" height="59" width="150"
            alt="A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/inductionbench/" >InductionBench: LLMs Fail in the Simplest Complexity Class</a>
    </div>

    
    <a href="/en/publication/inductionbench/"  class="summary-link">
      <div class="article-style">
        Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in which rules such as mathematical axioms or programming syntax are clearly defined, based on which LLMs can plan and apply these rules to arrive at a solution. In contrast, inductive reasoning, where one infers the underlying rules from observed data, remains less explored. Such inductive processes lie at the heart of scientific discovery, as they enable researchers to extract general principles from empirical observations. To assess whether LLMs possess this capacity, we introduce InductionBench, a new benchmark designed to evaluate the inductive reasoning ability of LLMs. Our experimental findings reveal that even the most advanced models available struggle to master the simplest complexity classes within the subregular hierarchy of functions, highlighting a notable deficiency in current LLMs&rsquo; inductive reasoning capabilities. Coda and data are available <a href="https://github.com/Wenyueh/inductive_reasoning_benchmark" target="_blank" rel="noopener">this url</a>.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Tyler Wong</span>, <span >
      Fei Sun</span>, <span >
      Liangming Pan</span>, <span >
      Adam Jardine</span>, <span >
      William Yang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2502.15823" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/inductionbench/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/Wenyueh/inductive_reasoning_benchmark" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/inductionbench/" >
        <img src="/en/publication/inductionbench/featured_hu193f7da54dc1be71fc00f785461c7b3e_41754_1b1fb18df8a5a0ce0280abbaf835dead.webp" height="97" width="150"
            alt="InductionBench: LLMs Fail in the Simplest Complexity Class" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/RuleArena/" >Rulearena: A benchmark for rule-guided reasoning with llms in real-world scenarios</a>
    </div>

    
    <a href="/en/publication/RuleArena/"  class="summary-link">
      <div class="article-style">
        This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning. Covering three practical domains &ndash; airline baggage fees, NBA transactions, and tax regulations &ndash; RuleArena assesses LLMs&rsquo; proficiency in handling intricate natural language instructions that demand long-context understanding, logical reasoning, and accurate mathematical computation. Two key attributes distinguish RuleArena from traditional rule-based reasoning benchmarks &ndash; (1) it extends beyond standard first-order logic representations, and (2) it is grounded in authentic, practical scenarios, providing insights into the suitability and reliability of LLMs for real-world applications. Our findings reveal several notable limitations in LLMs &ndash; (1) they struggle to identify and apply the appropriate rules, frequently becoming confused by similar but distinct regulations, (2) they cannot consistently perform accurate mathematical computations, even when they correctly identify the relevant rules, and (3) in general, they perform poorly in the benchmark. These results highlight significant challenges in advancing LLMs&rsquo; rule-guided reasoning capabilities in real-life applications.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Ruiwen Zhou</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Liangming Pan</span>, <span >
      Sitao Cheng</span>, <span >
      Xiaobao Wu</span>, <span >
      En Yu</span>, <span >
      William Yang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2412.08972" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/RuleArena/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/skyriver-2000/RuleArena" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/RuleArena/" >
        <img src="/en/publication/RuleArena/featured_hu46e9047943b5abeec0331f96b3a29937_229315_bb629c3d9a300ca15c0918f79a1d9865.webp" height="96" width="150"
            alt="Rulearena: A benchmark for rule-guided reasoning with llms in real-world scenarios" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/disentangling_logic/" >Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities</a>
    </div>

    
    <a href="/en/publication/disentangling_logic/"  class="summary-link">
      <div class="article-style">
        This study intends to systematically disentangle pure logic reasoning and text understanding by investigating the contrast across abstract and contextualized logical problems from a comprehensive set of domains. We explore whether LLMs demonstrate genuine reasoning capabilities across various domains when the underlying logical structure remains constant. We focus on two main questions (1) Can abstract logical problems alone accurately benchmark an LLM&rsquo;s reasoning ability in real-world scenarios, disentangled from contextual support in practical settings? (2) Does fine-tuning LLMs on abstract logic problem generalize to contextualized logic problems and vice versa? To investigate these questions, we focus on standard propositional logic, specifically propositional deductive and abductive logic reasoning. In particular, we construct instantiated datasets for deductive and abductive reasoning with 4 levels of difficulty, encompassing 12 distinct categories or domains based on the categorization of Wikipedia. Our experiments aim to provide insights into disentangling context in logical reasoning and the true reasoning capabilities of LLMs and their generalization potential.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Kaijie Zhu</span>, <span >
      Lingyao Li</span>, <span >
      Lizhou Fan</span>, <span >
      Shuhang Lin</span>, <span >
      Mingyu Jin</span>, <span >
      Haochen Xue</span>, <span >
      Zelong Li</span>, <span >
      Jindong Wang</span>, <span >
      Yongfeng Zhang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2406.02787" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/disentangling_logic/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/agiresearch/ContextHub" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/disentangling_logic/" >
        <img src="/en/publication/disentangling_logic/featured_hub0d4e223939f6c49e5c147c1b532e5f3_699953_9718bab1ebab968b09f24beed31e7ffa.webp" height="100" width="150"
            alt="Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/emoji/" >EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs</a>
    </div>

    
    <a href="/en/publication/emoji/"  class="summary-link">
      <div class="article-style">
        Cloud-based Large Language Models (LLMs) such as ChatGPT have become increasingly integral to daily operations. Nevertheless, they also introduce privacy concerns &ndash; firstly, numerous studies underscore the risks to user privacy posed by jailbreaking cloud-based LLMs; secondly, the LLM service providers have access to all user data, which deters individuals from confidently utilizing such services. To address such concerns, we propose a simple yet effective paradigm, EmojiPrompt, to protect user privacy. At its core, EmojiPrompt performs generative transformation, obfuscating private data within prompts with linguistic and non-linguistic elements before submitting them to cloud-based LLMs. We evaluate EmojiPrompt’s performance across 8 datasets from various domains. We also propose simulated inference attacks to assess EmojiPrompt’s ability to preserve user privacy. The results demonstrate that EmojiPrompt effectively obfuscates user private data, while largely maintaining, or even enhancing, performances compared to the unobfuscated version. Furthermore, EmojiPrompt’s atomic-level obfuscation allows it to function exclusively with cloud-based LLMs. For source code, please refer to <a href="https://github.com/agiresearch/EmojiCrypt" target="_blank" rel="noopener">this url</a>.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Guo Lin</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Zhengting Wang</span>, <span >
      Mingyu Jin</span>, <span >
      Lizhou Fan</span>, <span >
      Yongfeng Zhang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://aclanthology.org/2025.naacl-long.614.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/emoji/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/agiresearch/EmojiCrypt" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/emoji/" >
        <img src="/en/publication/emoji/featured_hu489d082375f37b0fd0d8ada750041523_148201_5de13e15b21b4ad949fc954319cebc1e.webp" height="95" width="150"
            alt="EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/recoe/" >Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks</a>
    </div>

    
    <a href="/en/publication/recoe/"  class="summary-link">
      <div class="article-style">
        Current approaches of knowledge editing struggle to effectively propagate updates to interconnected facts. In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel reasoning-based benchmark &ndash; ReCoE (Reasoning-based Counterfactual Editing dataset) &ndash; which covers six common reasoning schemes in real world. We conduct a thorough analysis of existing knowledge editing techniques, including input augmentation, finetuning, and locate-and-edit. We found that all model editing methods show notably low performance on this dataset, especially in certain reasoning schemes. Our analysis over the chain-of-thought generation of edited models further uncover key reasons behind the inadequacy of existing knowledge editing methods from a reasoning standpoint, involving aspects on fact-wise editing, fact recall ability, and coherence in generation. We will make our benchmark publicly available.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Jiang Guo</span>, <span >
      Mingwen Dong</span>, <span >
      Henghui Zhu</span>, <span >
      Patrick Ng</span>, <span >
      Zhiguo Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2401.17585" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/recoe/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/recoe/" >
        <img src="/en/publication/recoe/featured_hu34631b3d78a227933319772d89a95a3d_300489_e24ab5f90b77b9b75866cf069dcf2570.webp" height="72" width="150"
            alt="Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/nphard/" >NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes</a>
    </div>

    
    <a href="/en/publication/nphard/"  class="summary-link">
      <div class="article-style">
        Complex reasoning ability is one of the most important features of current LLMs, which has also been leveraged to play an integral role in complex decision-making tasks. Therefore, the investigation into the reasoning capabilities of Large Language Models (LLMs) is critical &ndash; numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, current benchmarks are inadequate in offering a rigorous evaluation of the full extent of reasoning abilities that LLMs are capable of achieving. They are also prone to the risk of overfitting, as these benchmarks, being publicly accessible and static, allow models to potentially tailor their responses to specific benchmark metrics, thereby inflating their performance. Addressing these limitations, our research introduces a new benchmark, named NPHardEval. This benchmark is designed to evaluate the reasoning abilities of LLMs across a broad spectrum of 900 algorithmic questions, extending up to the NP-Hard complexity class. These questions are meticulously chosen to represent a wide range of complexity class below the NP-hard complexity class, offering a rigorous measure of the reasoning ability of LLMs. Through this study, we shed light on the current state of reasoning in LLMs, providing an objective and rigorous perspective through the comparison of LLMs&rsquo; performance across complex classes. Moreover, this benchmark is designed with a dynamic update mechanism, where the datapoints are refreshed on a monthly basis. Such regular updates play a crucial role in mitigating the risk of LLMs overfitting to the benchmark, promoting a more accurate and reliable assessment of their reasoning capabilities. The benchmark dataset and code of NPHardEval are available at <a href="https://github.com/casmlab/NPHardEval" target="_blank" rel="noopener">this https URL</a>.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Lizhou Fan</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Lingyao Li</span>, <span >
      Haoyang Ling</span>, <span >
      Yongfeng Zhang</span>, <span >
      Libby Hemphill</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2312.14890.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/nphard/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/casmlab/NPHardEval" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/nphard/" >
        <img src="/en/publication/nphard/featured_hud119e9e95585e6bffc262e698eddfb87_118430_dd447cb60d4bd324aac97aaf3c036cf8.webp" height="123" width="150"
            alt="NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/domino/" >Discover, Explanation, Improvement: Automatic Slice Detection Framework for Natural Language Processing</a>
    </div>

    
    <a href="/en/publication/domino/"  class="summary-link">
      <div class="article-style">
        Current natural language processing (NLP) models such as BERT and RoBERTa have achieved high overall performance, but they often make systematic errors due to bias or certain difficult features to learn. Thus research on slice detection models (SDM) which automatically identifies underperforming groups of datapoints has gradually caught more attention, which aims at both understanding model behaviors and providing insights for future model training and designing. However, there is little systematic research on SDM and quantitative evaluation of its assessment for NLP models. Our paper fills this gap by proposing &ldquo;Discover, Explanation, Improvement&rdquo; framework that discovers coherent and underperforming groups of datapoints and unites datapoints of each slice under human-understandable concepts; it also provides comprehensive evaluation tasks and the corresponding quantitative metrics, which enable convenient comparison for future works. Results show that our framework can accurately select error-prone datapoints with informative semantic features that summarize error patterns, based on which it directly boosts model performance by an average of 2.85 points based on trained models without tuning any parameters across multiple datasets.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Lifeng Jin</span>, <span >
      Lingfeng Song</span>, <span >
      Haitao Mi</span>, <span >
      Yongfeng Zhang</span>, <span >
      Dong Yu</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00617/118719" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/domino/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/Wenyueh/DEIM" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/domino/" >
        <img src="/en/publication/domino/featured_hu7f5b8bb12c5cf02183e2695b49e8e64a_543716_afddf8d73a65b519c16deace5cd2d23a.webp" height="63" width="150"
            alt="Discover, Explanation, Improvement: Automatic Slice Detection Framework for Natural Language Processing" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/system12/" >System 1&#43; System 2= Better World: Neural-Symbolic Chain of Logic Reasoning</a>
    </div>

    
    <a href="/en/publication/system12/"  class="summary-link">
      <div class="article-style">
        Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science—which proposes that human cognition process involves two stages &ndash; an intuitive, unconscious and fast process relying on perception calledSystem 1, and a logical, conscious and slow process performing complex reasoning called System 2—we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Yongfeng Zhang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://aclanthology.org/2022.findings-emnlp.42.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/system12/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/system12/" >
        <img src="/en/publication/system12/featured_hu23668bbea84150c56d7d8e5223524a11_263815_26bec27d076ab902d42b0266d1d3278e.webp" height="138" width="150"
            alt="System 1&#43; System 2= Better World: Neural-Symbolic Chain of Logic Reasoning" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/entqa/" >EntQA: Entity linking as question answering</a>
    </div>

    
    <a href="/en/publication/entqa/"  class="summary-link">
      <div class="article-style">
        A conventional approach to entity linking is to first find mentions in a given document and then infer their underlying entities in the knowledge base. A well-known limitation of this approach is that it requires finding mentions without knowing their entities, which is unnatural and difficult. We present a new model that does not suffer from this limitation called EntQA, which stands for Entity linking as Question Answering. EntQA first proposes candidate entities with a fast retrieval module, and then scrutinizes the document to find mentions of each candidate with a powerful reader module. Our approach combines progress in entity linking with that in open-domain question answering and capitalizes on pretrained models for dense entity retrieval and reading comprehension. Unlike in previous works, we do not rely on a mention-candidates dictionary or large-scale weak supervision. EntQA achieves strong results on the GERBIL benchmarking platform.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Wenzheng Zhang</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Karl Stratos</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://https://arxiv.org/pdf/2110.02369.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/entqa/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/WenzhengZhang/EntQA" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/entqa/" >
        <img src="/en/publication/entqa/featured_hu1805a7e44e77f9e662fbd264f9f7cf67_315896_c23104c2d043675f7e5bb50b29fc30fd.webp" height="73" width="150"
            alt="EntQA: Entity linking as question answering" loading="lazy">
      </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/en/publication/predicate/" >A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression</a>
    </div>

    
    <a href="/en/publication/predicate/"  class="summary-link">
      <div class="article-style">
        Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution–Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Mingming Sun</span>, <span class="author-highlighted">
      Wenyue Hua</span>, <span >
      Zoey Liu</span>, <span >
      Xin Wang</span>, <span >
      Kangjie Zheng</span>, <span >
      Ping Li</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/en/publication/predicate/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://sunbelbd.github.io/Open-Information-eXpression/" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://aclanthology.org/2020.emnlp-main.167.pdf" target="_blank" rel="noopener">
  Dataset
</a>



  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/en/project/LLM-NLP/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/en/publication/predicate/" >
        <img src="/en/publication/predicate/featured_hua848399a9a1337038de2b867e36a42e9_338602_6df6fca4c333e9d0ca3e28aa89e1dfe1.webp" height="53" width="150"
            alt="A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression" loading="lazy">
      </a>
    
  </div>
</div>

        
      

      
      
      
    </div>
  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  <p class="powered-by copyright-license-text">
    © 2025 Wenyue Hua.
  </p>
  





  <p class="powered-by">
    
    
    
      
      
      
        
        
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.7a0c53d11be409aa2bde72889a671bd9.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
